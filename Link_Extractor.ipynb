{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Link Extractor\n",
        "\n",
        "This program extracts links from STATIC webpages and puts them in a Markdown file named links.md.\n",
        "\n",
        "If using this in Colab, open the files browser on the left pane. You may have to refresh the files browser after running the program to see the links.md file.\n",
        "\n",
        "Scroll down past the code for a full description of the program's operation."
      ],
      "metadata": {
        "id": "dGVI4jPE3huS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVcrnLR600gt",
        "outputId": "6ccd91bd-bb4b-4b0e-839f-fafbca4ed1b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Links have been saved to links.md, sorted alphabetically by title without duplicates.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from pathlib import Path\n",
        "\n",
        "# The URL you want to scrape\n",
        "url = 'https://www.google.com/'\n",
        "def running_in_notebook():\n",
        "    try:\n",
        "        from IPython import get_ipython\n",
        "        if get_ipython() is None:\n",
        "            return False  # Not in an IPython environment\n",
        "        if 'IPKernelApp' not in get_ipython().config:\n",
        "            return False  # IPython is running, but not under a kernel\n",
        "    except (ImportError, AttributeError):\n",
        "        return False  # IPython is not installed or other attribute errors\n",
        "    return True\n",
        "\n",
        "# Fetch the web page\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()  # Check for request success\n",
        "\n",
        "# Parse the HTML content\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Initialize a dictionary to store links with href as key to avoid duplicates\n",
        "links_dict = {}\n",
        "\n",
        "# Extract all links and store in the dictionary to ensure uniqueness\n",
        "for link in soup.find_all('a'):\n",
        "    href = link.get('href')\n",
        "    text = link.text.strip()\n",
        "    if href and text and href not in links_dict:  # Check if href is already included\n",
        "        links_dict[href] = text\n",
        "\n",
        "# Sort links by the link text (title)\n",
        "sorted_links = sorted(links_dict.items(), key=lambda item: item[1].lower())\n",
        "\n",
        "# Use this function to adjust behavior based on environment\n",
        "if running_in_notebook():\n",
        "    # Jupyter notebook specific code\n",
        "    from pathlib import Path\n",
        "    file_path = Path('links.md')  # Example: Specify path for Jupyter notebook environment\n",
        "else:\n",
        "    # Code for non-notebook environment\n",
        "    from pathlib import Path\n",
        "    script_dir = Path(__file__).resolve().parent\n",
        "    file_path = script_dir / 'links.md'  # Example: Specify path for standalone script\n",
        "\n",
        "# Write the links to a Markdown file\n",
        "with open(file_path, 'w', encoding='utf-8') as file:\n",
        "    for href, text in sorted_links:\n",
        "        # fix the part(s) of the URL that Colab inserts\n",
        "        href = href.replace('https://www.google.com/url?q=', '')\n",
        "        href = href.split('&')[0]\n",
        "        file.write(f\"- {text} - {href}\\n\")\n",
        "\n",
        "print(\"Links have been saved to links.md, sorted alphabetically by title without duplicates.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a fully commented breakdown of the code, including explanations of its components:\n",
        "\n",
        "**Imports**\n",
        "\n",
        "* **requests:** A powerful library for making HTTP requests to websites and fetching their content.\n",
        "* **bs4 (BeautifulSoup):** A library for parsing HTML and XML documents. It makes it easy to navigate and extract data from web pages.\n",
        "* **pathlib:** A module providing classes to work with file system paths in a platform-independent way.\n",
        "\n",
        "**Function: running_in_notebook()**\n",
        "\n",
        "* **Purpose:** This function detects if the code is running within a Jupyter Notebook environment.  This is useful for potentially modifying file save locations based on the execution context.\n",
        "* **How it works:**\n",
        "    * Tries to import `IPython` (the core of Jupyter Notebooks).\n",
        "    * If successful, checks if the environment is an IPython kernel.\n",
        "    * Returns `True` if both conditions are met, `False` otherwise.\n",
        "\n",
        "**Web Scraping: the main logic**\n",
        "\n",
        "* **url:** The target website to scrape (in this case, Google's homepage).\n",
        "\n",
        "* **requests.get(url):**\n",
        "    * Sends an HTTP GET request to the specified `url`.\n",
        "    * Stores the server's response in the `response` object.\n",
        "\n",
        "* **response.raise_for_status():**\n",
        "    * Checks if the request was successful. Raises an exception for error status codes (e.g., 404 Not Found).\n",
        "\n",
        "* **BeautifulSoup(response.text, 'html.parser'):**\n",
        "    * Creates a `BeautifulSoup` object, parsing the HTML content of the response using the `html.parser`.\n",
        "    * `soup` now represents a structured way to navigate the HTML.\n",
        "\n",
        "* **links_dict = {}:**\n",
        "    * Initializes an empty dictionary to store unique links (key = `href` attribute,  value = link text).\n",
        "\n",
        "* **for link in soup.find_all('a'): ...**\n",
        "    * Iterates over all anchor tags (`<a>`) within the HTML.\n",
        "    * **href = link.get('href'):** Extracts the `href` attribute.\n",
        "    * **text = link.text.strip():** Extracts the text content of the link and removes leading/trailing spaces.\n",
        "    * **if href and text and href not in links_dict:**  Ensures a valid `href` and text exist, and the link hasn't been seen before (prevents duplicates).\n",
        "        * **links_dict[href] = text:**  Adds the link to the dictionary.\n",
        "\n",
        "* **sorted_links = ...:**\n",
        "    * Sorts the items in the `links_dict` as a list of (href, text) tuples.\n",
        "    * Sorting is done alphabetically (case-insensitive) by the link text.\n",
        "\n",
        "**Environment-Based Behavior**\n",
        "\n",
        "* **if running_in_notebook(): ... else: ...**\n",
        "    * Determines file path based on whether the code is running in a notebook or as a standalone script.\n",
        "    * **Jupyter Notebook:**  Sets a simple file name 'links.md' (likely in the same directory as the notebook).\n",
        "    * **Standalone Script:**  Calculates the path relative to the current script's location.\n",
        "\n",
        "**Saving Links to Markdown**\n",
        "\n",
        "* **with open(file_path, 'w', encoding='utf-8') as file:** ...\n",
        "    * Opens the specified file in write mode (`'w'`) with UTF-8 encoding.\n",
        "    * **for href, text in sorted_links:** Iterates through the sorted links.\n",
        "        * **href modification:** This part attempts to remove extra bits that might be added to links when clicked via Google search results. You may or may not need it depending on your goal.\n",
        "        * **file.write(f\"- {text} - {href}\\n\"):** Writes each link in Markdown list format to the file.\n",
        "\n",
        "* **print(...):**  Provides confirmation of success.\n",
        "\n"
      ],
      "metadata": {
        "id": "mqW3JmavwAMi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OCDRSUmPwL34"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}